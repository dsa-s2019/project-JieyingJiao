sPGA_12week=sPGA-rbinom(n=1831,1,0.7)
for (i in 1:309){
PSI_12week[i]=ceiling(rnorm(1,PSI[i]*0.92,sd=0.2))
}
ss=sample(1:309,25)
PSI_12week[ss[1:2]]=0
PSI_12week[ss[3:25]]= floor(PSI[ss[3:25]]*runif(23,0.03,0.22))
for (i in 310:609){
PSI_12week[i]=ceiling(rnorm(1,PSI[i]*0.3,sd=0.3))
}
ss=sample(310:609,210)
PSI_12week[ss[1:65]]=0
PSI_12week[ss[66:210]]= floor(PSI[ss[66:210]]*runif(145,0.18,0.22))
sPGA_12week[ss[1:65]]=0
sPGA_12week[ss[66:183]]=1
for (i in 610:1219){
PSI_12week[i]=ceiling(rnorm(1,PSI[i]*0.33,sd=0.3))
}
ss=sample(610:1219,406)
PSI_12week[ss[1:157]]=0
PSI_12week[ss[158:406]]= floor(PSI[ss[158:406]]*runif(249,0.18,0.22))
sPGA_12week[ss[1:157]]=0
sPGA_12week[ss[158:354]]=1
for (i in 1220:1831){
PSI_12week[i]=ceiling(rnorm(1,PSI[i]*0.14,sd=0.3))
}
ss=sample(1220:1831,528)
PSI_12week[ss[1:272]]=0
PSI_12week[ss[273:344]]= floor(PSI[ss[273:344]]*runif(72,0.3,0.5))
sPGA_12week[ss[1:272]]=0
sPGA_12week[ss[272:481]]=1
sPGA_12week
sPGA_12week[1220:1831]==1
sum(sPGA_12week[1220:1831]==1)
AMAGINE=c(rep(1,309),rep(2,300),rep(3,610),rep(4,528))
PSI_12week[1220:1831]/PSI[1220:1831]
sum(PSI_12week[1220:1831]/PSI[1220:1831]<=0.25)
PSI_12week[ss[273:336]]= floor(PSI[ss[273:336]]*runif(64,0.3,0.5))
sum(PSI_12week[1220:1831]/PSI[1220:1831]<=0.25)
PSI_12week[ss[273:320]]= floor(PSI[ss[273:320]]*runif(48,0.3,0.5))
sum(PSI_12week[1220:1831]/PSI[1220:1831]<=0.25)
PSI_12week[ss[273:300]]= floor(PSI[ss[273:300]]*runif(28,0.3,0.5))
sum(PSI_12week[1220:1831]/PSI[1220:1831]<=0.25)
sum(PSI_12week[1220:1831]/PSI[1220:1831]<=0.25)
PSI_12week[ss[401:408]]=floor(PSI[ss[401:408]]*runif(8,0.35,0.45))
sum(PSI_12week[1220:1831]/PSI[1220:1831]<=0.25)
ID=1:1831
phase3=data.frame(ID,age,sex,weight,PSI,PSI_12week,sPGA,sPGA_12week,AMAGINE)
AMAGINE=c(rep(1,309),rep(2,300),rep(3,610),rep(4,612))
phase3=data.frame(ID,age,sex,weight,PSI,PSI_12week,sPGA,sPGA_12week,AMAGINE)
head(phase3)
write.csv(phase3,file='phase3.csv')
install.packages('devtools')
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'Admin user password')
install.packages(as.vector(needed_packages))
/Library/Frameworks/R.framework/Versions/x.xx/Resources/library
installed.packages()
update.packages(checkBuilt=TRUE)
update.packages()
packs = as.data.frame(installed.packages(.libPaths()[1]), stringsAsFactors = F)
## and now re-install install packages using install.packages()
install.packages(packs$Package)
install.packages(packs$Package)
install.packages(packs$Package)
install.packages(packs$Package)
install.packages(packs$Package)
install.packages(packs$Package)
remove.packages()
update.packages(checkBuilt=TRUE)
require(nimble)
installed.packages()
update.packages(checkBuilt=TRUE)
y
y
y
install.packages(c("caTools", "curl", "energy", "evaluate", "fda", "foreign", "git2r", "igraph", "nimble", "pillar", "polyclip", "RCurl", "spatstat", "spatstat.data", "spatstat.utils", "stringi", "survival", "tinytex", "utf8", "withr", "yaml"))
require(nimble)
packageStatus()
install.packages('ggplot2')
install.packages('coda')
install.packages("coda")
require(abc.data)
data(huma)
data(human)
data(stat.obs)
data(ppc)
ppc
View(stat.voight)
View(stat.3pops.sim)
install.packages("quantmod") #Install the quantmod library
install.packages("quantmod")
library("quantmod")
startDate = as.Date("2008-01-13") #Specify period of time we are interested in
endDate = as.Date("2012-01-12")
tickers <- c("ARM","CSR") #Define the tickers we are interested in
#Download the stock history (for all tickers)
getSymbols(tickers, env = stockData, src = "yahoo", from = startDate, to = endDate)
load("/Users/neal/Dropbox/SCS16022/data-2017.Rdata")
age=ceiling(rnorm(n=1831,mean=45,sd=13))
weight=age+rnorm(n=1831,mean=46,sd=18)
sex=rbinom(n=1831,1, 0.69)
race=rbinom(n=1831,1, 0.9)
body_index=rnorm(n=1831,mean=30.6,sd=7.2)
PSI=ceiling(runif(n=1831,min=10,max=38))-4
sPGA=rep(4,1831)
sPGA[order(PSI,decreasing=FALSE)[1:994]]=3
sPGA[order(PSI,decreasing=TRUE)[1:114]]=5
PSI_12week=rep(0,1831)
sPGA_12week=sPGA-rbinom(n=1831,1,0.7)
for (i in 1:309){
PSI_12week[i]=ceiling(rnorm(1,PSI[i]*0.92,sd=0.2))
}
ss=sample(1:309,25)
PSI_12week[ss[1:2]]=0
PSI_12week[ss[3:25]]= floor(PSI[ss[3:25]]*runif(23,0.03,0.22))
for (i in 310:609){
PSI_12week[i]=ceiling(rnorm(1,PSI[i]*0.3,sd=0.3))
}
ss=sample(310:609,210)
PSI_12week[ss[1:65]]=0
PSI_12week[ss[66:210]]= floor(PSI[ss[66:210]]*runif(145,0.18,0.22))
sPGA_12week[ss[1:65]]=0
sPGA_12week[ss[66:183]]=1
for (i in 610:1219){
PSI_12week[i]=ceiling(rnorm(1,PSI[i]*0.33,sd=0.3))
}
ss=sample(610:1219,406)
PSI_12week[ss[1:157]]=0
PSI_12week[ss[158:406]]= floor(PSI[ss[158:406]]*runif(249,0.18,0.22))
sPGA_12week[ss[1:157]]=0
sPGA_12week[ss[158:354]]=1
for (i in 1220:1831){
PSI_12week[i]=ceiling(rnorm(1,PSI[i]*0.14,sd=0.3))
}
ss=sample(1220:1831,528)
PSI_12week[ss[401:408]]=floor(PSI[ss[401:408]]*runif(8,0.35,0.45))
PSI_12week[ss[1:272]]=0
sPGA_12week[ss[1:272]]=0
sPGA_12week[ss[272:481]]=1
library("Rcpp", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
remove.packages("Rcpp")
remove.packages("rlang")
install.packages('rlang')
install.packages('tibble')
library(haven)
cy6_ms_cmb_stu_qq2 <- read_sas("Desktop/PUF_SAS_COMBINED_CMB_STU_QQQ/cy6_ms_cmb_stu_qq2.sas7bdat",
NULL)
View(cy6_ms_cmb_stu_qq2)
install.packages(c("digest", "energy", "fansi", "igraph", "nimble", "openssl", "pkgconfig", "polyclip", "rlang", "scales", "spatstat", "spatstat.utils", "tinytex"))
install.packages('readxl')
library(readxl)
globalterrorismdb_0617dist <- read_excel("Downloads/globalterrorismdb_0617dist.xlsx")
View(globalterrorismdb_0617dist)
View(globalterrorismdb_0617dist)
library(MASS)
library (tmvtnorm)
Sigma <- matrix(c(1, .1, .1, 1), 2)  # Covariance matrix
X1 <- rtmvt(n=1000, mean=rep(0, 2), sigma = Sigma, df=2) # from tmvtnorm package
t.kde <- kde2d(X1[,1], X1[,2], n = 50)   # from MASS package
col2 <- heat.colors(length(bivn.kde$z))[rank(bivn.kde$z)]
persp3d(x=t.kde, col = col2)
install.packages('tmvtnorm')
library (tmvtnorm)
Sigma <- matrix(c(1, .1, .1, 1), 2)  # Covariance matrix
X1 <- rtmvt(n=1000, mean=rep(0, 2), sigma = Sigma, df=2) # from tmvtnorm package
t.kde <- kde2d(X1[,1], X1[,2], n = 50)   # from MASS package
col2 <- heat.colors(length(bivn.kde$z))[rank(bivn.kde$z)]
persp3d(x=t.kde, col = col2)
q()
load("~/Downloads/covtype.data")
covtype <- read.csv("~/Downloads/covtype.data", header=FALSE)
View(covtype)
load("~/Downloads/covtype.libsvm.binary")
covtype.libsvm <- read.table("~/Downloads/covtype.libsvm.binary", quote="\"", comment.char="")
View(covtype.libsvm)
covtype.libsvm <- read.table("~/Downloads/covtype.libsvm.binary", quote="\"", comment.char="")
View(covtype.libsvm)
covtype.libsvm.binary <- read.table("~/Downloads/covtype.libsvm.binary.scale", quote="\"", comment.char="")
View(covtype.libsvm.binary)
load("~/Downloads/covtype.libsvm.binary.scale")
covtype <- read.csv("~/Downloads/covtype.csv")
View(covtype)
unique(covtype$Cover_Type)
table(covtype$Cover_Type)
load("~/Dropbox/energystats-fall-2018-spring-2019/data/outdata/datasets/babbidge_library.Rdata")
View(df.st)
View(covtype)
arima.sim(model=list(Ar=-0.5),n=400)
arima.sim(model=list(Ar=0.5),n=400)
x=arima.sim(model=list(Ar=0.5),n=400)
sum(x[2:400]*x[1:399])/sum(x[2:400]*x[2:400])
sum(x[2:400]*x[1:399])
x[2:400]*x[1:399]
sum(x[2:400]*x[1:399])
sum(x[2:400]*x[2:400])
sum(x[2:400]*x[1:399])/sum(x[1:399]*x[1:399])
x=arima.sim(model=list(Ar=0.5),n=1000)
x
x[1:999]*x[1:999]
sum(x[2:1000]*x[1:999])/sum(x[1:999]*x[1:999])
acf(x)
lm(x[2:1000]~x[1:999])
lm(x[2:1000]~x[1:999]-1)
print(acf(arima.sim(model=list(ar=-0.5),n=400))
)
x=arima.sim(model=list(Ar=-0.5),n=1000)
sum(x[2:1000]*x[1:999])/sum(x[1:999]*x[1:999])
arima.sim(list(order=c(1,0,0), ar=.5), n=1000)
x=arima.sim(list(order=c(1,0,0), ar=.5), n=1000)
x
sum(x[2:1000]*x[1:999])/sum(x[1:999]*x[1:999])
sum(x[1:999]*x[1:999])
lm(x[2:1000]~x[1:999]-1)
summary(lm(x[2:1000]~x[1:999]-1))
sqrt(1/sum(x[1:999]*x[1:999]))
kronecker
?kronecker
get(wd)
require(nimble)
## Not run:
pumpCode <- nimbleCode({
for (i in 1:N){
theta[i] ~ dgamma(alpha,beta);
lambda[i] <- theta[i]*t[i];
x[i] ~ dpois(lambda[i])
}
alpha ~ dexp(1.0);
beta ~ dgamma(0.1,1.0);
})
pumpConsts <- list(N = 10,
t = c(94.3, 15.7, 62.9, 126, 5.24,
31.4, 1.05, 1.05, 2.1, 10.5))
pumpData <- list(x = c(5, 1, 5, 14, 3, 19, 1, 1, 4, 22))
pumpInits <- list(alpha = 1, beta = 1,
theta = rep(0.1, pumpConsts$N))
pumpModel <- nimbleModel(code = pumpCode, name = 'pump', constants = pumpConsts,
data = pumpData, inits = pumpInits)
# Want to maximize alpha and beta (both which must be positive) and integrate over theta
box = list( list(c('alpha','beta'), c(0, Inf)))
pumpMCEM <- buildMCEM(model = pumpModel, latentNodes = 'theta[1:10]',
boxConstraints = box)
MLEs <- pumpMCEM$run(initM = 1000)
MLEs
setwd("~/Dropbox/sports_point_process/real_data")
rm(list=ls())
require(nimble)
library(ggplot2)
library(rjson)
library(grid)
library(jpeg)
library(RCurl)
###=============================================================================
### data visualization
##=============================================================================
shotdata <- read.csv("nba_savant201939 (1).csv")
ggplot(data = shotdata, aes(x = x, y = y)) + geom_point(aes(colour = as.factor(shot_made_flag)))
## half court image, delete 8 obs that are beyond half court
shotdata <- shotdata[shotdata$y <= 420, ]
courtImg.URL <- "https://thedatagame.files.wordpress.com/2016/03/nba_court.jpg"
court <- rasterGrob(readJPEG(getURLContent(courtImg.URL)),
width=unit(1,"npc"), height=unit(1,"npc"))
ggplot(shotdata, aes(x=x, y=y)) +
annotation_custom(court, -250, 250, -50, 420) +
geom_point(aes(colour = as.factor(shot_made_flag))) + xlim(-250, 250) + ylim(-50, 420)
x <- (shotdata$x + 250) / 500
y <- (shotdata$y + 50) / 470
distance <- (shotdata$shot_distance) / 40
## marks model: period(treat as integer), seconds_left(minutes*60+seconds),
##              shot_type(factor), opponent(factor)
seconds <- shotdata$minutes_remaining * 60 + shotdata$seconds_remaining
## creat dummy variables for shot_type and opponent
shot_type <- model.matrix(~shotdata$shot_type)[, -1]
opponent <- model.matrix(~shotdata$opponent)[, -1]
code <- nimbleCode({
beta1 ~ dnorm(0, sd = 10)
beta2 ~ dnorm(0, sd = 10)
beta3 ~ dnorm(0, sd = 10)
lambda0 ~ dgamma(0.01, 0.01)
for (i in 1:N1) alpha[i] ~ dnorm(0, sd = 10)
for (i in 1:100) {
for (j in 1:100) {
for (k in 1:100) {
## 0.01: since true data window is [0, 1]
lambda_D[i, j, k] <- lambda0 * exp(beta1*0.01*i + beta2*0.01*j + beta3*0.01*k)
}
}
}
s_ll <- mean(lambda_D[1:100, 1:100, 1:100])
for (i in 1:N) {
lambda[i] <- lambda0 * exp(beta1 * x[i] + beta2 * y[i] + beta3 * distance[i])
mark_logit[i] <- alpha[1]*lambda[i]/100 + alpha[2]*period[i] +
alpha[3]*seconds[i] + alpha[4]*shot_type[i]
for (j in 1:(N1-4)) mark_logit[i] <- mark_logit[i] + alpha[4+j]*opponent[i, j]
## log-likelihood for i-th mark
logmark[i] <- -mark[i] * log(1+exp(-mark_logit[i])) +
(1 - mark[i]) * (-mark_logit[i] - log(1+exp(-mark_logit[i])))
}
ll_m <- sum(logmark[1:N])
log_ll <- sum(log(lambda[1:N]))
})
##' define log-likelihood
llFun <- nimbleFunction(
setup <- function(model) {},
run <- function() {
ll_m <- model$ll_m
s_ll <- model$s_ll
log_ll <- model$log_ll
ll <- ll_m - s_ll + log_ll
returnType(double())
return(ll[1])
}
)
constants <- list(N1 = 4 + ncol(opponent),
N = nrow(shotdata))
data <- list(
x = x,
y = y,
distance = distance,
mark = shotdata$shot_made_flag,
period = shotdata$period,
seconds = seconds,
shot_type = shot_type,
opponent = opponent
)
## initial value of MCMC sampling
inits <- list(beta1 = 0, beta2 = 0, beta3 = 0, lambda0 = 1,
alpha = rep(0, constants$N1))
Rmodel <- nimbleModel(code = code, constants = constants, data = data,
inits = inits, check = FALSE)
rm(list=ls())
require(nimble)
library(ggplot2)
library(rjson)
library(grid)
library(jpeg)
library(RCurl)
###=============================================================================
### data visualization
##=============================================================================
shotdata <- read.csv("nba_savant201939 (1).csv")
ggplot(data = shotdata, aes(x = x, y = y)) + geom_point(aes(colour = as.factor(shot_made_flag)))
## half court image, delete 8 obs that are beyond half court
shotdata <- shotdata[shotdata$y <= 420, ]
courtImg.URL <- "https://thedatagame.files.wordpress.com/2016/03/nba_court.jpg"
court <- rasterGrob(readJPEG(getURLContent(courtImg.URL)),
width=unit(1,"npc"), height=unit(1,"npc"))
ggplot(shotdata, aes(x=x, y=y)) +
annotation_custom(court, -250, 250, -50, 420) +
geom_point(aes(colour = as.factor(shot_made_flag))) + xlim(-250, 250) + ylim(-50, 420)
## full model
## intensity model: x, y, distance
## convert x y and distance into [0, 1] scale
x <- (shotdata$x + 250) / 500
y <- (shotdata$y + 50) / 470
distance <- (shotdata$shot_distance) / 40
## marks model: period(treat as integer), seconds_left(minutes*60+seconds),
##              shot_type(factor), opponent(factor)
seconds <- shotdata$minutes_remaining * 60 + shotdata$seconds_remaining
## creat dummy variables for shot_type and opponent
shot_type <- model.matrix(~shotdata$shot_type)[, -1]
opponent <- model.matrix(~shotdata$opponent)[, -1]
code <- nimbleCode({
beta1 ~ dnorm(0, sd = 10)
beta2 ~ dnorm(0, sd = 10)
beta3 ~ dnorm(0, sd = 10)
lambda0 ~ dgamma(0.01, 0.01)
for (i in 1:N1) alpha[i] ~ dnorm(0, sd = 10)
for (i in 1:100) {
for (j in 1:100) {
for (k in 1:100) {
## 0.01: since true data window is [0, 1]
lambda_D[i, j, k] <- lambda0 * exp(beta1*0.01*i + beta2*0.01*j + beta3*0.01*k)
}
}
}
s_ll <- mean(lambda_D[1:100, 1:100, 1:100])
for (i in 1:N) {
lambda[i] <- lambda0 * exp(beta1 * x[i] + beta2 * y[i] + beta3 * distance[i])
mark_logit[i] <- alpha[1]*lambda[i]/100 + alpha[2]*period[i] +
alpha[3]*seconds[i] + alpha[4]*shot_type[i]
for (j in 1:(N1-4)) {mark_logit[i] <- mark_logit[i] + alpha[4+j]*opponent[i, j]}
## log-likelihood for i-th mark
logmark[i] <- -mark[i] * log(1+exp(-mark_logit[i])) +
(1 - mark[i]) * (-mark_logit[i] - log(1+exp(-mark_logit[i])))
}
ll_m <- sum(logmark[1:N])
log_ll <- sum(log(lambda[1:N]))
})
##' define log-likelihood
llFun <- nimbleFunction(
setup <- function(model) {},
run <- function() {
ll_m <- model$ll_m
s_ll <- model$s_ll
log_ll <- model$log_ll
ll <- ll_m - s_ll + log_ll
returnType(double())
return(ll[1])
}
)
constants <- list(N1 = 4 + ncol(opponent),
N = nrow(shotdata))
data <- list(
x = x,
y = y,
distance = distance,
mark = shotdata$shot_made_flag,
period = shotdata$period,
seconds = seconds,
shot_type = shot_type,
opponent = opponent
)
## initial value of MCMC sampling
inits <- list(beta1 = 0, beta2 = 0, beta3 = 0, lambda0 = 1,
alpha = rep(0, constants$N1))
Rmodel <- nimbleModel(code = code, constants = constants, data = data,
inits = inits, check = FALSE)
rm(list=ls())
require(nimble)
library(ggplot2)
library(rjson)
library(grid)
library(jpeg)
library(RCurl)
###=============================================================================
### data visualization
##=============================================================================
shotdata <- read.csv("nba_savant201939 (1).csv")
ggplot(data = shotdata, aes(x = x, y = y)) + geom_point(aes(colour = as.factor(shot_made_flag)))
## half court image, delete 8 obs that are beyond half court
shotdata <- shotdata[shotdata$y <= 420, ]
courtImg.URL <- "https://thedatagame.files.wordpress.com/2016/03/nba_court.jpg"
court <- rasterGrob(readJPEG(getURLContent(courtImg.URL)),
width=unit(1,"npc"), height=unit(1,"npc"))
ggplot(shotdata, aes(x=x, y=y)) +
annotation_custom(court, -250, 250, -50, 420) +
geom_point(aes(colour = as.factor(shot_made_flag))) + xlim(-250, 250) + ylim(-50, 420)
## full model
## intensity model: x, y, distance
## convert x y and distance into [0, 1] scale
x <- (shotdata$x + 250) / 500
y <- (shotdata$y + 50) / 470
distance <- (shotdata$shot_distance) / 40
## marks model: period(treat as integer), seconds_left(minutes*60+seconds),
##              shot_type(factor), opponent(factor)
seconds <- shotdata$minutes_remaining * 60 + shotdata$seconds_remaining
## creat dummy variables for shot_type and opponent
shot_type <- model.matrix(~shotdata$shot_type)[, -1]
opponent <- model.matrix(~shotdata$opponent)[, -1]
code <- nimbleCode({
beta1 ~ dnorm(0, sd = 10)
beta2 ~ dnorm(0, sd = 10)
beta3 ~ dnorm(0, sd = 10)
lambda0 ~ dgamma(0.01, 0.01)
for (i in 1:N1) alpha[i] ~ dnorm(0, sd = 10)
for (i in 1:100) {
for (j in 1:100) {
for (k in 1:100) {
## 0.01: since true data window is [0, 1]
lambda_D[i, j, k] <- lambda0 * exp(beta1*0.01*i + beta2*0.01*j + beta3*0.01*k)
}
}
}
s_ll <- mean(lambda_D[1:100, 1:100, 1:100])
for (i in 1:N) {
lambda[i] <- lambda0 * exp(beta1 * x[i] + beta2 * y[i] + beta3 * distance[i])
mark_logit[i] <- alpha[1]*lambda[i]/100 + alpha[2]*period[i] +
alpha[3]*seconds[i] + alpha[4]*shot_type[i]
# for (j in 1:(N1-4))  {
#  mark_logit[i] <- mark_logit[i] + alpha[4+j]*opponent[i, j]
#  }
## log-likelihood for i-th mark
logmark[i] <- -mark[i] * log(1+exp(-mark_logit[i])) +
(1 - mark[i]) * (-mark_logit[i] - log(1+exp(-mark_logit[i])))
}
ll_m <- sum(logmark[1:N])
log_ll <- sum(log(lambda[1:N]))
})
##' define log-likelihood
llFun <- nimbleFunction(
setup <- function(model) {},
run <- function() {
ll_m <- model$ll_m
s_ll <- model$s_ll
log_ll <- model$log_ll
ll <- ll_m - s_ll + log_ll
returnType(double())
return(ll[1])
}
)
constants <- list(N1 = 4 + ncol(opponent),
N = nrow(shotdata))
data <- list(
x = x,
y = y,
distance = distance,
mark = shotdata$shot_made_flag,
period = shotdata$period,
seconds = seconds,
shot_type = shot_type,
opponent = opponent
)
## initial value of MCMC sampling
inits <- list(beta1 = 0, beta2 = 0, beta3 = 0, lambda0 = 1,
alpha = rep(0, constants$N1))
Rmodel <- nimbleModel(code = code, constants = constants, data = data,
inits = inits, check = FALSE)
shot_type
install.packages('rjson')
